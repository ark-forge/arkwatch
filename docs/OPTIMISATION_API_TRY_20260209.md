# Optimisation Endpoint `/api/try` - Analyse Technique
**Date**: 2026-02-09
**Endpoint**: POST /api/try
**Performance actuelle**: 980ms
**Objectif**: <500ms (id√©alement <300ms)

## Analyse du Code

### Op√©rations Co√ªteuses Identifi√©es

```python
# Ligne 225-235: Requ√™te HTTP vers URL externe (PRINCIPALE CAUSE)
async with httpx.AsyncClient(timeout=15, ...) as client:
    response = await client.get(url)  # ‚Üê 800-900ms en moyenne
```

**Probl√®me**: D√©pend enti√®rement de la latence du site cible.

```python
# Ligne 215: Check SSL synchrone (convertie en thread)
ssl_future = asyncio.to_thread(_get_ssl_info, hostname, port)  # ‚Üê 50-100ms
```

**Probl√®me**: Timeout SSL √† 5s (ligne 66), peut bloquer longtemps.

```python
# Ligne 258-264: Parsing HTML pour extraire <title>
text = response.text[:10000]  # ‚Üê 20-50ms pour gros HTML
```

**Probl√®me**: Parsing manuel de HTML, pas optimis√©.

## Solutions Recommand√©es (par ordre de priorit√©)

### üî¥ PRIORIT√â 1: Cache Redis (Gain estim√©: 80-90%)

**Impact**: R√©duire 980ms ‚Üí 100-150ms pour URLs d√©j√† test√©es

**Impl√©mentation**:
```python
import redis
import hashlib

redis_client = redis.Redis(host='localhost', port=6379, db=0)
CACHE_TTL = 1800  # 30 minutes

def _get_cache_key(url: str) -> str:
    return f"try:{hashlib.md5(url.encode()).hexdigest()}"

@router.post("/try")
async def try_check(request_body: TryCheckRequest, request: Request):
    url = str(request_body.url)
    cache_key = _get_cache_key(url)

    # Check cache
    cached = redis_client.get(cache_key)
    if cached:
        return TryCheckResponse.parse_raw(cached)

    # ... existing check logic ...

    # Store in cache
    response_json = result.json()
    redis_client.setex(cache_key, CACHE_TTL, response_json)
    return result
```

**Avantages**:
- R√©ponse instantan√©e pour URLs populaires
- R√©duit charge serveur
- TTL court (30min) = donn√©es fra√Æches

**Installation**: `pip install redis` + service Redis

---

### üü° PRIORIT√â 2: Timeout plus agressif (Gain estim√©: 30-40%)

**Impact**: √âviter attentes >5s sur sites lents

**Impl√©mentation**:
```python
# Ligne 226: R√©duire timeout de 15s ‚Üí 8s
async with httpx.AsyncClient(
    timeout=httpx.Timeout(8.0, connect=3.0, read=5.0),  # ‚Üê 8s total, 3s connect, 5s read
    follow_redirects=True,
    ...
) as client:
```

**Avantages**:
- R√©ponse max 8s au lieu de 15s
- Am√©liore UX (feedback rapide)
- Sites lents marqu√©s "down" rapidement

---

### üü° PRIORIT√â 3: Optimiser SSL Check (Gain estim√©: 20%)

**Impact**: R√©duire 50-100ms ‚Üí 20-30ms

**Impl√©mentation**:
```python
# Ligne 66: Timeout SSL plus court
with socket.create_connection((hostname, port), timeout=2) as sock:  # ‚Üê 2s au lieu de 5s
```

**Avantages**:
- SSL check plus rapide
- Timeout coh√©rent avec HTTP timeout

---

### üü¢ PRIORIT√â 4: Optimiser parsing HTML (Gain estim√©: 10%)

**Impact**: R√©duire 20-50ms ‚Üí 5-10ms

**Impl√©mentation**:
```python
# Option 1: Regex simple (plus rapide que find manuel)
import re
title_match = re.search(r'<title[^>]*>([^<]+)</title>', text[:10000], re.IGNORECASE)
title = title_match.group(1).strip()[:200] if title_match else None

# Option 2: Limiter taille t√©l√©charg√©e (√©conomise aussi bande passante)
# Ligne 258: Lire seulement premiers KB
async with httpx.AsyncClient(...) as client:
    async with client.stream("GET", url) as response:
        chunks = []
        async for chunk in response.aiter_bytes():
            chunks.append(chunk)
            if sum(len(c) for c in chunks) > 50000:  # Stop at 50KB
                break
        content = b"".join(chunks)
```

**Avantages**:
- Parsing plus rapide
- √âconomie bande passante
- Moins de m√©moire utilis√©e

---

### üü¢ PRIORIT√â 5: Response streaming (Gain UX: √©norme)

**Impact**: Feedback imm√©diat utilisateur

**Impl√©mentation** (architecture avanc√©e):
```python
from fastapi.responses import StreamingResponse

@router.post("/try")
async def try_check(request_body: TryCheckRequest, request: Request):
    async def generate():
        # Envoyer imm√©diatement r√©ponse partielle
        yield json.dumps({"status": "checking", "url": url}) + "\n"

        # Faire check HTTP
        result = await _do_http_check(url)
        yield json.dumps({"status": "partial", "http": result}) + "\n"

        # Faire check SSL
        ssl_result = await _do_ssl_check(url)
        yield json.dumps({"status": "complete", "http": result, "ssl": ssl_result}) + "\n"

    return StreamingResponse(generate(), media_type="application/x-ndjson")
```

**Avantages**:
- UX am√©lior√©e (feedback progressif)
- Utilisateur voit r√©sultat HTTP imm√©diatement
- SSL peut arriver apr√®s sans bloquer

---

## Plan d'Impl√©mentation Recommand√©

### Phase 1: Quick Wins (1-2h)
1. ‚úÖ R√©duire timeout HTTP (15s ‚Üí 8s)
2. ‚úÖ R√©duire timeout SSL (5s ‚Üí 2s)
3. ‚úÖ Optimiser parsing HTML (regex)

**Gain estim√©**: 980ms ‚Üí 600-700ms

### Phase 2: Cache Redis (2-3h)
1. ‚úÖ Installer Redis sur serveur
2. ‚úÖ Impl√©menter cache avec TTL 30min
3. ‚úÖ Tester invalidation cache

**Gain estim√©**: 600ms ‚Üí 100-150ms (pour hits)

### Phase 3: Optimisations avanc√©es (optionnel, 4-6h)
1. Streaming response
2. Pre-fetch populaires URLs
3. CDN pour API (Cloudflare Workers)

**Gain estim√©**: <100ms per√ßu

---

## Benchmark Cible Post-Optimisation

| Sc√©nario | Avant | Apr√®s (Phase 1) | Apr√®s (Phase 2) | Objectif |
|----------|-------|-----------------|-----------------|----------|
| Cache HIT | 980ms | 980ms | **100ms** | ‚úÖ <500ms |
| Cache MISS - Site rapide | 980ms | **400ms** | 400ms | ‚úÖ <500ms |
| Cache MISS - Site lent | 980ms | **700ms** | 700ms | ‚ö†Ô∏è Acceptable |
| Cache MISS - Site down | 15000ms | **8000ms** | 8000ms | ‚úÖ Timeout rapide |

---

## Tests de Validation

```bash
# Test 1: Mesurer avant optimisation
curl -w "@curl-format.txt" -X POST https://watch.arkforge.fr/api/try \
  -H "Content-Type: application/json" \
  -d '{"url": "https://example.com"}'

# Test 2: Mesurer apr√®s Phase 1
# (r√©p√©ter commande)

# Test 3: Mesurer cache hit (Phase 2)
# (r√©p√©ter 2x m√™me URL, 2√®me doit √™tre <150ms)

# Test 4: Load test
ab -n 100 -c 10 -p request.json -T application/json https://watch.arkforge.fr/api/try
```

**Fichier curl-format.txt**:
```
time_total: %{time_total}s
time_connect: %{time_connect}s
time_starttransfer: %{time_starttransfer}s
```

---

## Risques & Mitigations

### Risque 1: Cache stale data
- **Mitigation**: TTL court (30min)
- **Monitoring**: Logger cache hit rate

### Risque 2: Redis down
- **Mitigation**: Fallback graceful (ignorer cache si erreur)
```python
try:
    cached = redis_client.get(cache_key)
except redis.ConnectionError:
    cached = None  # Fallback: skip cache
```

### Risque 3: Timeout trop court
- **Mitigation**: Diff√©rencier timeout/error dans r√©ponse
- **UX**: "Site took >8s, marked as slow" vs "Site unreachable"

---

## Conclusion

**Effort estim√©**: 3-5h (Phases 1+2)
**Gain attendu**: 980ms ‚Üí 100-400ms (60-90% am√©lioration)
**ROI**: TR√àS √âLEV√â (endpoint critique conversion)

**Recommandation CEO**: Impl√©menter Phases 1+2 imm√©diatement (priorit√© P1).
